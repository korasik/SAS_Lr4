# SAS_Lr4

Для начала подключим 1 кнопку и 1 светодиод, реализуем получение изображения с usb камеры с распознаванием на нем человека. При обнаружении на изображении человека, будем включать светодиод, при отсутствии человека на изображении -- выключать. По нажатию кнопки будем прекращать слежение.

Подключим кнопку и светодиод по следующей схеме:

![](https://github.com/korasik/SAS_Lr4/blob/master/lr4_cam_id_bb-1.jpg)

Для обработки нажатий на кнопку воспользуемся прерываниями (реализованны в библиотеке RPi.GPIO начиная с версии 0.5.0а), а точнее мультипоточный обратный отклик (threaded callback), поскольку данная функция выполняется в отдельном потоке и следит за наступлением ожидаемого события, и работа основной программы в первом потоке не блокируется в момент выполнения функции во втором.

Стоит обратить внимание на то, что в данной работе используется нумерация BOARD для пинов, поскольку это упрощает их поиск на одноплатном компьютере Raspberry Pi.

Рассмотрим код, отвечающий за обработку события нажатия на кнопку:
```python
GPIO.add_event_detect(BUTTON_PIN, GPIO.RISING, bouncetime=300)
GPIO.add_event_callback(BUTTON_PIN, on_off_ident)
```

Метод "GPIO.add_event_detect" запускает второй поток, который следит за изменением уровня сигнала на BUTTON_PIN и при его смене с низкого на высокий (RISING) запускает функцию *on_off_ident* (листинг см. ниже), указанную в параметрах метода "GPIO.add_event_callback".
```python
def on_off_ident(channel):
global on_off_id
if on_off_id == 0:
    print('Identification ON')
    on_off_id = 1
else:
    print('Identification OFF')
    on_off_id = 0
```

В случае если глобальная переменная *on_off_id* равна 1, то выполняется соответствующая ветка, отвечающая за распознавание лица человека и выводящая сообщение "Detection ON" (листинг функции приведен ниже).
```python
cv2.putText(img, str('Detection ON'), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)
```

Иначе мы выключаем светодиод и выводим сообщение "Detection OFF":
```python
GPIO.output(LED_PIN, False)
cv2.putText(img, str('Detection OFF'), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)
```

Метод "cv2.putText" выводит необходимое сообщение в окне с изображением с камеры. В нашем случае мы также устанавливаем зеленый и красный цвет текста для надписей "Detection ON" и "Detection OFF" соответственно и располагаем их в левом верхнем углу.

Из-за невозможности использовать имеющиеся сервомоторы поворот камеры не был реализован и был заменен на вывод сообщений в консоль о том, в какую сторону необходимо повернуть камеру. Код, отвечающий за эти сообщения, приведен ниже:

```python
for (x,y,w,h) in faces:
    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)
    roi_gray = gray[y:y+h, x:x+w]
    roi_color = img[y:y+h, x:x+w]
    if x + (w / 2) < prev_x - 40:
        print('Turn LEFT')
        prev_x = x + (w / 2)
    if x + (w / 2) > prev_x + 40:
        print('Turn RIGHT')
        prev_x = x + (w / 2)
```

Данный код расположен в цикле, который строит рамку вокруг распознанного объекта. Здесь мы сравниваем положение центральной точки объекта с предыдущим значением, из которого вычитается или к которому прибавляется 40 (это сделано для тех случаев, когда человек случайно дергает головой в сторону, т.е. это запас).

При использовании сервомотора необходимо заменить строки `print('Turn RIGHT')` и `print('Turn LEFT')` на соответствующие методы; а также необходимо убрать или закомментировать строки `prev_x = x + (w / 2)`, поскольку в нашем случае камера была неподвижна, и мы сравнивали положение объекта в кадре с его предыдущим положением, а не с положением центра. Переменная *prev_x* изначально имеет значение 320, т.е. это центр кадра по оси x.
